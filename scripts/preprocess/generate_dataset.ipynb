{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2cd4ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd/n",
    "import json/n",
    "from pathlib import Path/n",
    "/n",
    "EVENTS_PATH = Path(/"../../data/processed/events.json/")/n",
    "REPORTS_PATH = Path(/"../../data/processed/reports.json/")/n",
    "OUTPUT_PATH = Path(/"../../data/processed/dataset.json/")/n",
    "/n",
    "events_df = pd.read_json(EVENTS_PATH)/n",
    "reports_df = pd.read_json(REPORTS_PATH)/n",
    "/n",
    "events_df['timestamp'] = pd.to_datetime(events_df['timestamp'], errors='coerce')/n",
    "reports_df['timestamp'] = pd.to_datetime(reports_df['timestamp'], errors='coerce')/n",
    "/n",
    "# We asumme events.json and reports.json are already sorted/n",
    "# events_df = events_df.sort_values('timestamp')/n",
    "# reports_df = reports_df.sort_values('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f1e9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re/n",
    "/n",
    "def unique_sentences(text):/n",
    "    if not text:/n",
    "        return /"/"/n",
    "    /n",
    "    # Use regex to split on ., !, ? followed by space or end of string/n",
    "    raw_sentences = re.split(r'(?<=[.!?;])//s+(?=[A-ZŠŽČĆĐ])', text.strip())/n",
    "/n",
    "    seen = set()/n",
    "    unique = []/n",
    "/n",
    "    for s in raw_sentences:/n",
    "        normalized = s.strip().rstrip('.!?').strip().lower()/n",
    "        if normalized and normalized not in seen:/n",
    "            seen.add(normalized)/n",
    "            unique.append(s.strip())/n",
    "/n",
    "    return /" /".join(unique)/n",
    "/n",
    "def get_events_in_interval(after_time, before_time):/n",
    "/n",
    "    if after_time is None:/n",
    "        filtered = events_df[events_df['timestamp'] <= before_time]/n",
    "    else:/n",
    "        filtered = events_df[(events_df['timestamp'] > after_time) & (events_df['timestamp'] <= before_time)]/n",
    "/n",
    "    # Initialize dictionary with empty lists/n",
    "    events = {/n",
    "        /"Pomembno/": [],/n",
    "        /"Nesreče/": [],/n",
    "        /"Zastoji/": [],/n",
    "        /"Vreme/": [],/n",
    "        /"Ovire/": [],/n",
    "        /"Dela/": [],/n",
    "        /"Mejni prehodi/": [],/n",
    "        /"Opozorila/": []/n",
    "    }/n",
    "/n",
    "    # Map labels to dataframe columns/n",
    "    label_to_column = {/n",
    "        /"Pomembno/": /"important_text/",/n",
    "        /"Nesreče/": /"accident_text/",/n",
    "        /"Zastoji/": /"traffic_jam_text/",/n",
    "        /"Vreme/": /"weather_text/",/n",
    "        /"Ovire/": /"obstacle_text/",/n",
    "        /"Dela/": /"roadwork_text/",/n",
    "        /"Mejni prehodi/": /"intl_info_text/",/n",
    "        /"Opozorila/": /"warnings_text/"/n",
    "    }/n",
    "/n",
    "    for _, row in filtered.iterrows():/n",
    "        for label, column in label_to_column.items():/n",
    "            value = str(row.get(column, '')).strip().strip(/",/")/n",
    "            if value and not value.endswith(('.', '!', '?')):/n",
    "                value += '.'/n",
    "            if value:/n",
    "                events[label].append(value)/n",
    "/n",
    "    return events/n",
    "/n",
    "def format_events(events):/n",
    "    parts = []/n",
    "    for label, texts in events.items():/n",
    "        full_text = unique_sentences(/" /".join(texts))/n",
    "        if full_text:  # Only add section if there are any texts/n",
    "            section = f/"{label.upper()}: /" + full_text/n",
    "            parts.append(section)/n",
    "/n",
    "    return /" /".join(parts) /n",
    "/n",
    "training_dataset = []/n",
    "current_time = None/n",
    "for _, report in reports_df.iterrows():/n",
    "    events = get_events_in_interval(current_time, report[/"timestamp/"])/n",
    "    events_text = format_events(events)/n",
    "    cleaned_output = report['report'].strip()/n",
    "    if events_text:/n",
    "        training_dataset.append({/n",
    "            /"input/": events_text,/n",
    "            /"groundtruth/": cleaned_output/n",
    "        })/n",
    "/n",
    "    current_time = report['timestamp']/n",
    "/n",
    "len(training_dataset)/n",
    "# training_dataset[0]/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c59defcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported 7947 samples to ..//..//data//processed//dataset.json/n"
     ]
    }
   ],
   "source": [
    "import json/n",
    "/n",
    "with open(OUTPUT_PATH, /"w/", encoding=/"utf-8/") as f:/n",
    "    json.dump(training_dataset, f, ensure_ascii=False, indent=2)/n",
    "/n",
    "print(f/"Exported {len(training_dataset)} samples to {OUTPUT_PATH}/")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
